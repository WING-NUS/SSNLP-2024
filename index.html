<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description"
          content="SSNLP 2024">
    <meta name="author" content="">
    <meta name="keywords"
          content="SSNLP 2024, Singapore Symposium">
    <title>SSNLP 2024: The 2024 Singapore Symposium on Natural Language Processing
    </title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/scrolling-nav.css" rel="stylesheet">

    <link rel="shortcut icon" type="image/x-icon" href="favicon.png">

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <link rel="stylesheet" type="text/css" href="fonts/font-awesome-4.7.0/css/font-awesome.min.css">
    <!--===============================================================================================-->
    <link rel="stylesheet" type="text/css" href="vendor/animate/animate.css">
    <!--===============================================================================================-->
    <link rel="stylesheet" type="text/css" href="vendor/select2/select2.min.css">
    <!--===============================================================================================-->
    <link rel="stylesheet" type="text/css" href="vendor/perfect-scrollbar/perfect-scrollbar.css">
    <!--===============================================================================================-->
    <link rel="stylesheet" type="text/css" href="css/util.css">
    <link rel="stylesheet" type="text/css" href="css/main.css">

    <style type="text/css">
        .navbar-text > a {
            color: inherit;
            text-decoration: none;
        }

        .white_bg {
            background-color: #eef7fa;
            padding: 3px;
        }

        .line2 {
            margin: 5px 0;
            height: 2px;
            background: repeating-linear-gradient(to right, black 0, black 10px, transparent 10px, transparent 12px)
            /*10px red then 2px transparent -> repeat this!*/
        }

        .bordered, .hover2, xximg:hover {
            border-color: #AAAAAA;
            border-style: solid;
            border-width: 1px;
            border-collapse: separate /* otherwise does not work in IE inside tables */;
        }

        .hover2 {
            -webkit-box-shadow: 2px 2px 2px rgba(, , 120, 0.6);
            -moz-box-shadow: 2px 2px 2px rgba(, , 120, 0.6);
            -o-box-shadow: 2px 2px 2px rgba(, , 120, 0.6);
            box-shadow: 0px 0px 10px rgba(, , 120, 0.6);
        }

        figure figcaption {
            text-align: center;
            margin: 10px;
        }

        figure {
            display: inline-block;
            margin: 0px;
        }

        figure img {
            vertical-align: top;
            border: 1px solid #ddd;
            border-radius: 0px;
            padding: 0px;
        }

        figure img:hover {
            opacity: 0.7;
            filter: alpha(opacity=70);
            -webkit-box-shadow: -2px 4px 10px 0px rgba(0, 0, 0, 1);
            -moz-box-shadow: -2px 4px 10px 0px rgba(0, 0, 0, 1);
            box-shadow: -2px 4px 10px 0px rgba(0, 0, 0, 1);
            -webkit-transition: all .2s ease-in-out;
            transition: all .2s ease-in-out;

        }
    </style>
</head>

<body id="page-top">

<!-- Navigation -->
<nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
    <div class="container">
        <div class="navbar-header">
            <a class="navbar-brand js-scroll-trigger" href="#">
                SSNLP 2024
            </a>
        </div>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive"
                aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
            <ul class="navbar-nav ml-auto">
                <li class="nav-item">
                    <a class="nav-link js-scroll-trigger" href="#overview">Overview</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link js-scroll-trigger" href="#programme">Programme</a>
                </li>
<!-- Speakers -->
                <li class="nav-item">
                    <a class="nav-link js-scroll-trigger" href="#organizers">Organizers</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link js-scroll-trigger" href="#partners">Partners</a>
                </li>
<!-- Partners, Photos -->
                <li class="nav-item">
                    <a class="nav-link js-scroll-trigger" href="#location">Location</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link js-scroll-trigger" href="#past-ssnlp">Past SSNLP</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link js-scroll-trigger" href="#contact">Contact</a>
                </li>
            </ul>
        </div>
    </div>
</nav>

<header class="bg-primary text-white">
    <div class="container text-center">
        <h1 style="font-size: 60px;font-weight: bold;color: #e48a52;">SSNLP 2024</h1>
        <h2 style="font-size: 35px;color: #ffffff;background-color: rgba(0, 123, 255, .25);">The 2024 Singapore Symposium on Natural Language Processing</h2>
    </div>
</header>

<section id="overview" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h2>Welcome!</h2>
                <p style="text-align: justify;">We are excited to announce that the <b>Singapore Symposium on Natural Language Processing (SSNLP 2024)</b> will take place on <b>Wednesday, November 6</b>, as a full-day event. 
			SSNLP, an annual pre-conference workshop, gathers the Natural Language Processing community in Singapore, 
			bringing together local students, practitioners, and faculty. It offers a valuable platform to connect, exchange ideas, and foster collaboration.
              <!--    [ <a href="https://www.comp.nus.edu.sg/maps/photos#com1">Map</A> ]
                  [ <a href="https://www.comp.nus.edu.sg/images/resources/content/mapsvenues/COM1_L2.jpg">Floorplan</A> ]-->
                </p>

    	<p style="text-align: justify;">
		Since its inception in 2018, SSNLP has steadily grown in both popularity and influence, with successful editions held in 2018, 2019, 2020, 2022, and 2023. 
		We look forward to continuing this tradition in 2024 and delivering another impactful experience for all participants.
	</p>

                <p style="text-align: justify;">
			This year's event will be held at the <b>Mapletree Business City, Town Hall Auditorium, (10 Pasir Panjang Road, Singapore 117438,
                    [<a href="https://maps.app.goo.gl/iPgMZCrtKoc2nYzi7">Google Map</a>], [<a href="images/roadmap.png">Venue Roadmap</a>],
                    [<a href="images/town-hall-1.jpg">Outdoor photo</a>], [<a href="images/town-hall-2.jpg">Indoor photo</a>])</b>.
		    Please note that seating is limited. In the event of oversubscription, we may consider virtual attendance for registered participants. 
			We encourage early bird registration to secure your spot.
			</p>
                <center>
                  <p>
                    <a href="https://forms.office.com/r/4RVt9GXPFD" target="_blank" class="btn btn-primary">Registration here</a>
                  </p>
                </center>

<!--                 <p>Due to fire code restrictions, our venues cannot accommodate additional onsite registrations.  However, we have plenty of capacity for virtual attendance.  Feel free to request the link for the virtual registration below.
                </p> -->

		    
<!-- 		    <p>Right now, our in-person registration is closed, but feel free to make virtual registrations for online attendance by dropping an email. We will send you a Zoom link.</p>
                <center>
                  <p>
                    <a href="https://docs.google.com/forms/d/e/1FAIpQLScBFhd2XQf8ciLpRcNPAlim3mFXLc4CpDxTn-8Cef3AKd5j9Q/viewform?pli=1" target="_blank" class="btn disabled btn-secondary">Virtual Registration closed</a> -->

			  
<!--                     <a href="mailto:haofei37@nus.edu.sg?subject=SSNLP 2023 Virtual Registration&body=Hi, I'd like to receive the Zoom link for the upcoming SSNLP event on 5 December 2023.  Can you send it to me?  Thank you!" target="_blank" class="btn btn-primary">Register to get the Virtual Attendance Zoom links</a> -->
                  </p>
                </center>

                <h3>Latest news</h3>
                <br>
<!--                   <p><span class="white_bg"><strong>Dec 19, 2023</strong> — All the Posters and relevant materials can be downloaded from <a href="https://drive.google.com/drive/folders/1Njknx9-8A1Vk2d40vP7Pmce6_6tTDAQ3?usp=sharing-->
<!--">here.</a></span></p>-->
<!--                   <p><span class="white_bg"><strong>Nov 30, 2023</strong> — Program is confirmed, see you all</span></p>-->
                  <p><span class="white_bg"><strong>Oct 20, 2024</strong> — Registration is open, please register now</span></p>
                   <p><span class="white_bg"><strong>Oct 15, 2024</strong> — The date is confirmed: November 6, 2024</span></p>

            </div>
        </div>
    </div>
</section>

<section id="programme" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h2>Programme</h2>

		<p style="text-align: justify;">We've planned to host Oral and Post sessions for paper presentations, and also have invited Keynote Presentations as well as Industry Talks.</p>
	    	
                <div class="container-table100">
                    <div class="wrap-table100">

                        <div class="table100 ver5 m-b-10">
                            <table data-vertable="ver5">
                                <thead>
                                <tr class="row100 head">
                                    <th class="column100 column1" data-column="column1"><strong>Time</strong></th>
                                    <th class="column100 column2" data-column="column2"><strong>Event</strong></th>
                                </tr>
                                </thead>
                                <tbody>

                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">09:00 - 09:15</td>
                                    <td class="column100 column2" data-column="column2"><strong>Welcome and Opening
                                        Remarks</strong>
<!-- 					    <br> <em>introducer:</em> &nbsp; [TBD]  &nbsp;  &nbsp; -->
				    </td>
                                </tr>

                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">9.15 - 10:15</td>
                                    <td class="column100 column2" data-column="column2">
                                        <a style="color: #D90D0DFF;">
                                            <strong>Remote Keynote 1 (45mins + 15mins Q&A)</strong>
                                        </a>
                                        <br> <em>speaker:</em> &nbsp; <font color="red">Jason Wei</font>
                                    </td>
                                </tr>

<!--                                 <tr class="row100">
                                    <td class="column100 column1" data-column="column1">09:30 - 10:30</td>
                                    <td class="column100 column2" data-column="column2"><strong>Tea Break</strong></td>
                                </tr> -->

                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">10:30 - 11:30</td>
                                    <td class="column100 column2" data-column="column2">
                                        <a style="color: #d90d0d;">
                                            <strong>Remote Keynote 2 and 3 (each 20mins + 10mins Q&A) </strong>
                                        </a>
                                        <br> <em>speakers:</em> &nbsp; <font color="red">Bing Liu</font> & <font color="red">Yue Zhang</font> &nbsp; &nbsp;
<!--					    <br> <em>session chair:</em> &nbsp; Nancy Chen &nbsp;  &nbsp;-->
<!-- 					    <em>chaired by:</em> &nbsp; Francis Bond -->
                                    </td>
                                </tr>

                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">11:45 - 12:45</td>
                                    <td class="column100 column2" data-column="column2">
                                        <a style="color: #000000;">
                                        <a style="color: #ffc107;">
                                            <strong>Research Oral Presentation 1 (each 12mins + 3mins Q&A)</strong>
                                        </a>
<!--					                <br> <em>session chair:</em> &nbsp; Sun Shuo &nbsp;  &nbsp;-->
<!--                                         <br>
                                        <em>speaker:</em> &nbsp; <font color="red">Heng Ji</font> &nbsp; :: &nbsp; <em>chaired
                                        by:</em> &nbsp; Nancy Chen -->
                                    </td>
                                </tr>


                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">12:45 - 14:00</td>
                                    <td class="column100 column2" data-column="column2">
                                            <a  style="color: #007bff;"><strong>Poster Session 1</strong> </a>  <br>
                                        <a  style="color: #00d754;"><strong>Lunch (w/ Career & Networking Session)</strong> </a>
<!--                                         <br> <em>speaker:</em> &nbsp; <font color="red">Eduard Hovy</font> &nbsp; ::
                                        &nbsp; <em>chaired by:</em> &nbsp; Li Haizhou -->
                                    </td>
                                </tr>


                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">14:00 - 15:30</td>
                                    <td class="column100 column2" data-column="column2">

                                        <a style="color: #bd00ef;">
                                            <strong>On-Site Industry Talks  (each 20mins + 10mins Q&A)</strong>
                                        </a>
                                        <br> <em>speakers:</em> &nbsp; <font color="red">Tianyu Pang</font> &
                                        <font color="red">Wenxuan Zhang</font> &
                                        <font color="red">Taifeng Wang</font>
<!--					    <br> <em>session chairs:</em> &nbsp; Suzanna Sia & Gao Wei &nbsp;  &nbsp;-->
				     </td>
                                </tr>


                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">15:30 - 16:45</td>
                                    <td class="column100 column2" data-column="column2">
                                        <a style="color: #007bff;">
                                            <strong>Poster Session 2</strong>
                                                        </a>
<!--                                        <br> <em>session chair:</em> &nbsp; Yanxia Qin&nbsp;  &nbsp;-->
                                        </td>
                                </tr>


                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">15:45 - 16:30</td>
                                    <td class="column100 column2" data-column="column2">
                                        <a  style="color: #ffc107;">
                                            <strong>Research Oral Presentation 2  (each 12mins + 3mins Q&A)</strong>
                                        </a>
<!--					                <br> <em>session chair:</em> &nbsp; Tan Qingyu &nbsp;  &nbsp;-->
<!-- 					    <br> <em>speaker:</em> &nbsp; <font color="red">Rada
                                        Mihalcea</font> &nbsp; :: &nbsp; <em>chaired by:</em> &nbsp; Francis Bond -->
                                    </td>
                                </tr>



                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">16:30 - 17:00</td>
                                    <td class="column100 column2" data-column="column2">
                                        <a style="color: #2bc94f;">
                                            <strong>Coffee break</strong>
                                                        </a>
<!--                                        <br> <em>session chair:</em> &nbsp; Yanxia Qin&nbsp;  &nbsp;-->
                                        </td>
                                </tr>


                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">17:00 - 17:45</td>
                                    <td class="column100 column2" data-column="column2">
                                        <a  style="color: #ffc107;">
                                            <strong>Research Oral Presentation 3  (each 12mins + 3mins Q&A)</strong>
                                        </a>
<!--					                <br> <em>session chair:</em> &nbsp; Tan Qingyu &nbsp;  &nbsp;-->
<!-- 					    <br> <em>speaker:</em> &nbsp; <font color="red">Rada
                                        Mihalcea</font> &nbsp; :: &nbsp; <em>chaired by:</em> &nbsp; Francis Bond -->
                                    </td>
                                </tr>

<!--                                -->
<!--                                <tr class="row100">-->
<!--                                    <td class="column100 column1" data-column="column1">14:00 - 15:00</td>-->
<!--                                    <td class="column100 column2" data-column="column2">-->
<!--                                        <a  style="color: #ffc107;">-->
<!--                                            <strong>Paper session 3</strong>-->
<!--                                        </a>					    -->
<!--					    <br> <em>session chair:</em> &nbsp; Taha Aksu &nbsp;  &nbsp;-->
<!--                                    </td>-->
<!--                                </tr>-->


<!--                                <tr class="row100">-->
<!--                                    <td class="column100 column1" data-column="column1">15:00 - 16:00</td>-->
<!--                                    <td class="column100 column2" data-column="column2">-->
<!--                                        <a style="color: #000000;">-->
<!--                                            <strong>Keynote 5 and Keynote 6 (each 20mins + 10mins Q&A) </strong>-->
<!--                                        </a>-->
<!--                                        <br> <em>speakers:</em> &nbsp; <font color="red">Diyi</font> & <font color="red">Joao</font>-->
<!--					    <br> <em>session chair:</em> &nbsp; Kokil Jaidka&nbsp;  &nbsp;-->
<!--&lt;!&ndash;                                         &nbsp; :: &nbsp; <em>chaired by:</em> &nbsp; Li Haizhou &ndash;&gt;-->
<!--				     </td>-->
<!--                                </tr>-->

                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">17:45 - 18:00</td>
                                    <td class="column100 column2" data-column="column2">

                                        <a style="color: #000000;">
                                            <strong>Closing</strong>
                                        </a>
				                    </td>
                                </tr>

<!--                                <tr class="row100">-->
<!--                                    <td class="column100 column1" data-column="column1">16:30 - 18:30</td>-->
<!--                                    <td class="column100 column2" data-column="column2">-->

<!--                                        <a style="color: #000000;">-->
<!--                                            <strong>Industry session: Speaker presentations (each 20mins + 10mins Q&A)</strong>-->
<!--                                        </a>-->
<!--                                        <br> <em>speakers:</em> &nbsp; <font color="red">Daniel</font> & <font color="red">Huda</font> & <font color="red">Alessandro</font> & <font color="red">Lidong</font>-->
<!--					    <br> <em>session chairs:</em> &nbsp; Suzanna Sia & Gao Wei &nbsp;  &nbsp;-->
<!--				     </td>-->
<!--                                </tr>-->

<!--                                 <tr class="row100">
                                    <td class="column100 column1" data-column="column1">18:00 - 18:30</td>
                                    <td class="column100 column2" data-column="column2"><strong>Townhall</strong>
                                    </td>
                                </tr> -->

                                <!--                                 <tr class="row100">
                                                                    <td class="column100 column1" data-column="column1">17:30 - 18:00</td>
                                                                    <td class="column100 column2" data-column="column2">
                                                                    </td>
                                                                </tr> -->

                                </tbody>

                            </table>
                        </div>
                    </div>
                </div>
		    

            </div>
        </div>
    </div>
</section>


<section id="speakers" class="bg-light">
    <div class="container">
        <div class="row">
		
            <div class="col-lg-8 mx-auto">
                <h3>Oral & Poster Papers</h3>
                <p style="text-align: justify;">
<!--                    Papers are mainly exported from the EMNLP 2023 and ACL 2023.-->
                    Oral papers are for 12 minutes plus 3 minutes for immediate questions. 
<!-- 		    Posters are short, workshop, work-in-progress papers or last-minute additions to our programme.  -->
			Poster boards can accommodate (1m x 1m) sized posters, in either portrait or landscape.
			We split all the posters into Poster session 1 and Poster session 2, divided as follows, with each containing 20 poster boards.
<!-- 			There will be ample time after a session to engage in the breaks directly after the session. Session chairs should record each session and check with the speakers if they want their post-recorded session made public. Questions will be solicited via crowdsourcing via Padlets. -->
                </p>	
		<div id="Oral" data-toggle="collapse" data-parent="#accordion1">
		    <a href="#Oral-list" data-toggle="collapse"><b>Click to see the paper list &darr;</b></a>

                <div class="accordion1" id="accordion1">
			
                    <div id="Oral-list" class="collapse" data-parent="#accordion1">
                        <div class="table ver5 m-b-10">
                            <table data-vertable="ver5">
                                <tbody>				
                                <tr class="row100">
					<td valign="middle" style="font-weight: bold;">Paper session 1 &nbsp;&nbsp;</td>
                                    <td class="column100" data-column="column1">
                                      <p style="text-align:left; font-size:small">
[1] Zhiyuan Hu, Chumin Liu, Xidong Feng, Yilun Zhao, See-Kiong Ng, Anh Tuan Luu, Junxian He, Pang Wei Koh, Bryan Hooi. <i>Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models. NeurIPS</i> (<b>Slot: <a style="color: red;">11:45 - 12:00</a></b>)<BR/> 
[2] Lin Xu, Zhiyuan Hu, Daquan Zhou, Hongyu Ren, Zhen Dong, Kurt Keutzer, See-Kiong Ng, Jiashi Feng. <i>MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration. EMNLP main</i> (<b>Slot: <a style="color: red;">12:00 - 12:15</a></b>)<BR/> 
[3] Xuan Zhang, Chao Du, Tianyu Pang, Qian Liu, Wei Gao, Min Lin. <i>Chain of Preference Optimization: Improving Chain-of-Thought Reasoning in LLMs. NeurIPS</i> (<b>Slot: <a style="color: red;">12:15 - 12:30</a></b>)<BR/> 
[4] Xiaobao Wu, Liangming Pan, William Yang Wang, Anh Tuan Luu. <i>AKEW: Assessing Knowledge Editing in the Wild. EMNLP main</i> (<b>Slot: <a style="color: red;">12:30 - 12:45</a></b>)<BR/>

											      
<!--                                         [1] Ye, Hai, & Xie, Qizhe, & Ng, Hwee Tou. <i>Multi-Source Test-Time Adaptation as Dueling Bandits for Extractive Question Answering</i> (<b>Slot: <a style="color: red;">08:15 - 08:30</a></b>)<BR/> -->
<!--                                        [2] Zhengyuan Liu, Yong Keong Yap, Hai Leong Chieu and Nancy F. Chen.  <i>Guiding Computational Stance Detection with Expanded Stance Triangle Framework</i> (<b>Slot: <a style="color: red;">08:30 - 08:45</a></b>)<BR/>-->
<!--                                        [3] Ahmed Masry*, Parsa Kavehzadeh*, Xuan Long Do, Enamul Hoque, Shafiq Joty. <i>UniChart: A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning</i> (<b>Slot: <a style="color: red;">08:45 - 09:00</a></b>)<BR/>-->
<!--                                        [4] Ibrahim Taha Aksu, Devamanyu Hazarika, Shikib Mehri, Seokhwan Kim, Dilek Hakkani-Tur, Yang Liu, Mahdi Namazifar. <i>CESAR: Automatic Induction of Compositional Instructions for Multi-turn Dialogs</i> (<b>Slot: <a style="color: red;">09:00 - 09:15</a></b>)<BR/>-->
                                        </p>
                                    </td>
                                </tr>

							
                                <tr class="row100">
					<td valign="middle" style="font-weight: bold;">Paper session 2 &nbsp;&nbsp;</td>
                                    <td class="column100" data-column="column1">
                                      <p style="text-align:left; font-size:small">
[1] Ming Shan Hee, Aditi Kumaresan, Roy Ka-Wei Lee. <i>Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning. EMNLP main</i> (<b>Slot: <a style="color: red;">15:45 - 16:00</a></b>)<BR/> 
[2] Yang Deng, Yong Zhao, Moxin Li, See-Kiong Ng, Tat-Seng Chua. <i>Don't Just Say "I Don't Know"! Self-aligning Large Language Models for Responding to Unknown Questions with Explanations. EMNLP main</i> (<b>Slot: <a style="color: red;">16:00 - 16:15</a></b>)<BR/> 
[3] Jiahao Ying, Yixin Cao, Yushi Bai, Qianru Sun, Bo Wang, Wei Tang, Zhaojun Ding, Yizhe Yang, Xuanjing Huang, Shuicheng Yan. <i>Automating Dataset Updates Towards Reliable and Timely Evaluation of Large Language Models. NeurIPS</i> (<b>Slot: <a style="color: red;">16:15 - 16:30</a></b>)<BR/>

<!--                                         [1] Hannan Cao, Liping Yuan, Yuchen Zhang, Hwee Tou Ng. <i>Unsupervised Grammatical Error Correction Rivaling Supervised Methods</i> (<b>Slot: <a style="color: red;">10:30 - 10:45</a></b>)<BR/> -->
<!--                                        [2] Moxin Li, Wenjie Wang, Fuli Feng, Yixin Cao, Jizhi Zhang, Tat-Seng Chua.  <i>Robust Prompt Optimization for Large Language Models Against Distribution Shifts</i> (<b>Slot: <a style="color: red;">10:45 - 11:00</a></b>)<BR/>-->
<!--                                        [3] Ratish Puduppully, Anoop Kunchukuttan, Raj Dabre, Ai Ti Aw, Nancy F. Chen. <i>Decomposed Prompting for Machine Translation between Related Languages using Large Language Models</i>  (<b>Slot: <a style="color: red;">11:00 - 11:15</a></b>)<BR/>-->
<!--                                        [4] Zhiyuan Liu, Sihang Li, Yanchen Luo, Hao Fei, Yixin Cao, Kenji Kawaguchi, Xiang Wang, Tat-Seng Chua.  <i>MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter.</i> (<b>Slot: <a style="color: red;">11:15 - 11:30</a></b>)<BR/>-->
                                        </p>
                                    </td>
                                </tr>

							
                                <tr class="row100">
					<td valign="middle" style="font-weight: bold;">Paper session 3 &nbsp;&nbsp;</td>
                                    <td class="column100" data-column="column1">
                                      <p style="text-align:left; font-size:small">
[1] Yew Ken Chia, Guizhen Chen, Weiwen Xu, Luu Anh Tuan, Soujanya Poria, Lidong Bing. <i>Reasoning Paths Optimization: Learning to Reason and Explore From Diverse Paths. EMNLP main</i> (<b>Slot: <a style="color: red;">17:00-17:15</a></b>)<BR/> 
[2] Yiran Zhao, Wenyue Zheng, Tianle Cai, Xuan Long Do, Kenji Kawaguchi, Anirudh Goyal, Michael Shieh. <i>Accelerating Greedy Coordinate Gradient and General Prompt Optimization via Probe Sampling. NeurIPS</i> (<b>Slot: <a style="color: red;">17:15-17:30</a></b>)<BR/> 
[3] Wenyang Hu, Yao Shu, Zongmin Yu, Zhaoxuan Wu, Xiaoqiang Lin, Zhongxiang Dai, See-Kiong Ng, Bryan Kian Hsiang Low. <i>Localized Zeroth-Order Prompt Optimization. NeurIPS spotlight</i> (<b>Slot: <a style="color: red;">17:30 - 17:45</a></b>)<BR/>
					      
<!--                                         [1] Jinggui Liang, Lizi Liao. <i>ClusterPrompt: Cluster Semantic Enhanced Prompt Learning for New Intent Discovery</i> (<b>Slot: <a style="color: red;">14:00 - 14:15</a></b>)<BR/> -->
<!--                                        [2] Zhiqiang Hu, Lei Wang, Yihuai Lan, Wanyu Xu, Ee-Peng Lim, Lidong Bing, Xing Xu, Soujanya Poria, Roy Ka-Wei Lee.  <i>LLM-Adapter: An Empirical Study of Adapter-based Parameter-Efficient Fine-Tuning for Large Language Models</i> (<b>Slot: <a style="color: red;">14:15 - 14:30</a></b>)<BR/>-->
<!--                                        [3] Minzhi Li, Taiwei Shi, Caleb Ziems, Min-Yen Kan, Nancy F Chen, Zhengyuan Liu, Diyi Yang.  <i>CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation</i> (<b>Slot: <a style="color: red;">14:30 - 14:45</a></b>)<BR/>-->
<!--                                        [4] Quanyu Long, Wenya Wang, Sinno Jialin Pan.  <i>Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context Learning</i> (<b>Slot: <a style="color: red;">14:45 - 15:00</a></b>)<BR/>-->
                                        </p>
                                    </td>
                                </tr>

							
                                <tr class="row100">
					<td valign="middle" style="font-weight: bold;">Poster session 1&nbsp;&nbsp;</td>
                                    <td class="column100" data-column="column1">
                                      <p style="text-align:left; font-size:small">
					[1] Yikang Pan, Liangming Pan, Wenhu Chen, Preslav Nakov, Min-Yen Kan. <i>On the Risk of Misinformation Pollution with Large Language Models</i> (<b>Board: <a style="color: red;">P101</a></b>)<BR/>
					
<!--					[2] Fengzhu Zeng, Wei Gao. <i>Prompt to be Consistent is Better than Self-Consistent? Few-Shot and Zero-Shot Fact Verification with Pre-trained Language Models</i> (<b>Board: <a style="color: red;">P102</a></b>)<BR/>-->
					
<!--					[3] Shuo Sun, Yuchen Zhang, Jiahuan Yan, Yuze GAO, Donovan Ong, Bin Chen, Jian Su. <i>Battle of the Large Language Models: Dolly vs LLaMA vs Vicuna vs Guanaco vs Bard vs ChatGPT - A Text-to-SQL Parsing Comparison</i> (<b>Board: <a style="color: red;">P105</a></b>)<BR/>-->
					
<!--					[4] Liangming Pan, Alon Albalak, Xinyi Wang, William Yang Wang. <i>Logic-LM: Empowering large language models with symbolic solvers for faithful logical reasoning</i> (<b>Board: <a style="color: red;">P106</a></b>)<BR/>-->
					
<!--					[5] Jiaxi Li and Wei Lu. <i>Contextual Distortion Reveals Constituency: Masked Language Models are Implicit Parsers</i> (<b>Board: <a style="color: red;">P109</a></b>)<BR/>-->
					
<!--					[6] Shaz Furniturewala, Abhinav Java, Surgan Jandial, Simra Shahid, Pragyan Banerjee, Balaji Krishnamurthy, Sumit Bhatia and Kokil Jaidka. <i>Evaluating the Efficacy of Prompting Techniques for Debiasing Language Model Outputs</i> (<b>Board: <a style="color: red;">P110</a></b>)<BR/>-->
					
<!--					[7] Tan, Qingyu, & Xu, Lu, & Bing, Lidong, & Ng, Hwee Tou. <i>Class-Adaptive Self-Training for Relation Extraction with Incompletely Annotated Training Data</i> (<b>Board: <a style="color: red;">P103</a></b>)<BR/>-->
					
<!--					[8] Yixi Ding, Yanxia Qin, Qian Liu, Min Yen Kan. <i>CocoSciSum: A Scientific Summarization Toolkit with Compositional Controllability</i> (<b>Board: <a style="color: red;">P104</a></b>)<BR/>-->
					
<!--					[9] Shaurya Rohatgi, Yanxia Qin, Benjamin Aw, Niranjana Unnithan, Min-Yen Kan. <i>The ACL OCL Corpus: Advancing Open Science in Computational Linguistics</i> (<b>Board: <a style="color: red;">P107</a></b>)<BR/>-->
					
<!--					[10] Xinyuan Lu, Liangming Pan, Qian Liu, Preslav Nakov, Min-Yen Kan. <i>SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables</i> (<b>Board: <a style="color: red;">P108</a></b>)<BR/>-->
					
<!--					[11] Yeo, Gerard., Jaidka K. <i>The PEACE-Reviews dataset: Modeling Cognitive Appraisals in Emotion Text Analysis</i> (<b>Board: <a style="color: red;">P111</a></b>)<BR/>-->
					
<!--					[12] Kankan Zhou, Eason Lai, Wei Bin Au Yeong, Kyriakos Mouratidis, Jing Jiang. <i>ROME: Evaluating Pre-trained Vision-Language Models on Reasoning beyond Visual Common Sense</i> (<b>Board: <a style="color: red;">P112</a></b>)<BR/>-->
					
<!--					[13] Xiaobing Sun, Jiaxi Li, and Wei Lu. <i>Unraveling Feature Extraction Mechanisms in Neural Networks</i> (<b>Board: <a style="color: red;">P113</a></b>)<BR/>-->
					      
                                        </p>
                                    </td>
                                </tr>

							
                                <tr class="row100">
					<td valign="middle" style="font-weight: bold;">Poster session 2&nbsp;&nbsp;</td>
                                    <td class="column100" data-column="column1">
                                      <p style="text-align:left; font-size:small">
					[1] Xuan Long Do, Bowei Zou, Shafiq Joty, Anh Tai Tran, Liangming Pan, Nancy F. Chen, Ai Ti Aw. <i>Modeling What-to-ask and How-to-ask for Answer unaware Conversational Question Generation</i> (<b>Board: <a style="color: red;">P201</a></b>)<BR/>
					
<!--					[2] Rui Cao, Jing Jiang. <i>Modularized Zero-shot VQA with Pre-trained Models</i> (<b>Board: <a style="color: red;">P202</a></b>)<BR/>-->
					
<!--					[3] Bin Wang, Zhengyuan Liu, Nancy F. Chen. <i>Instructive Dialogue Summarization with Query Aggregations</i> (<b>Board: <a style="color: red;">P205</a></b>)<BR/>-->
					
<!--					[4] Huy Quang Dao, Lizi Liao, Dung D. Le, Yuxiang Nie. <i>Reinforced Target-driven Conversational Promotion</i> (<b>Board: <a style="color: red;">P206</a></b>)<BR/>-->
					
<!--					[5] Ibrahim Taha Aksu, Min-Yen Kan and Nancy F. Chen. <i>Zero-shot Adaptive Prefixes for Dialogue State Tracking Domain Adaptation</i> (<b>Board: <a style="color: red;">P209</a></b>)<BR/>-->
					
<!--					[6] Guangsheng Bao, Zhiyang Teng, Hao Zhou, Jianhao Yan, Yue Zhang. <i>Non-Autoregressive Document-Level Machine Translation</i> (<b>Board: <a style="color: red;">P210</a></b>)<BR/>-->
					
<!--					[7] Liangming Pan, Xiaobao Wu, Xinyuan Lu, Anh Tuan Luu, William Yang Wang, Min-Yen Kan, Preslav Nakov. <i>Fact-Checking Complex Claims with Program-Guided Reasoning</i> (<b>Board: <a style="color: red;">P203</a></b>)<BR/>-->
					
<!--					[8] Muhammad Reza Qorib, Hwee Tou Ng. <i>System Combination via Quality Estimation for Grammatical Error Correction</i> (<b>Board: <a style="color: red;">P204</a></b>)<BR/>-->
					
<!--					[9] Tan, Qingyu, & Ng, Hwee Tou, & Bing, Lidong. <i>Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models</i> (<b>Board: <a style="color: red;">P207</a></b>)<BR/>-->
					
<!--					[10] Ruichao Yang, Wei Gao, Jing Ma, Zhiwei Yang. <i>WSDMS: Debunk Fake News via Weakly Supervised Detection of Misinforming Sentences with Contextualized Social Wisdom</i> (<b>Board: <a style="color: red;">P208</a></b>)<BR/>-->
					
<!--					[11] Ratish Puduppully, Parag Jain, Nancy F. Chen and Mark Steedman. <i>Multi-Document Summarization with Centroid-Based Pretraining</i> (<b>Board: <a style="color: red;">P211</a></b>)<BR/>-->
					
<!--					[12] Mathieu Ravaut, Shafiq Joty, Nancy F. Chen. <i>Unsupervised Summarization Re-ranking</i> (<b>Board: <a style="color: red;">P212</a></b>)<BR/>-->
					
<!--					[13] Zhiqiang Hu, Nancy F. Chen, Roy Ka-Wei Lee. <i>Adapter-TST: A Parameter Efficient Method for Multiple-Attribute Text Style Transfer</i> (<b>Board: <a style="color: red;">P213</a></b>)<BR/>-->
					      
                                        </p>
                                    </td>
                                </tr>

					
				</tbody>
                            </table>
                        </div>			    
                    </div>

                </div>
            </div>
        </div>
    </div>
</section>


<section id="speakers" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h3>Keynote Speakers</h3>
                <p>
                    The following speakers from both academia and industry are invited to give keynotes at SSNLP 2024.
                    Please click the profile image to view the detailed description of the talk.
                </p>

                <div class="accordion" id="accordion">
                    <div class="table-responsive">
                        <table class="table">
                            <tbody>
                            <tr align="center">
                                <td>
                                    <a href="#Preslav" data-toggle="collapse">
                                        <figure>
                                            <img src="images/speaker/jason-wei.png" class="hover2"  height="185">
                                            <figcaption><h5>Jason Wei</h5></figcaption>
                                        </figure>
                                    </a>
                                </td>
                                <td>
                                    <a href="#Farah" data-toggle="collapse">
                                        <figure>
                                            <img src="images/speaker/bing-liu.png" class="hover2" align="center"
                                                 height="185">
                                            <figcaption>
                                                <h5>Bing Liu</h5>
                                            </figcaption>
                                        </figure>
                                    </a>
                                </td>
                                <td>
                                    <a href="#Yue" data-toggle="collapse">
                                        <figure>
                                            <img src="images/speaker/yuezhang.png" class="hover2" align="center"
                                                 height="185">
                                            <figcaption>
                                                <h5>Yue Zhang</h5>
                                            </figcaption>
                                        </figure>
                                    </a>
                                </td>
<!--                                 <td>
                                    <a href="#Vivian" data-toggle="collapse">
                                        <figure>
                                            <img src="images/speaker/Vivian-Chen.jpg" class="hover2" height="185">
                                            <figcaption><h5>Vivian Chen</h5></figcaption>
                                        </figure>
                                    </a>
                                </td>

                                <td>
                                    <a href="#Tanya" data-toggle="collapse">
                                        <figure>
                                            <img src="images/speaker/tanya-goyal.jpeg" class="hover2"
                                                  height="185">
                                            <figcaption><h5>Tanya Goyal</h5></figcaption>
                                        </figure>
                                    </a>
                                </td> -->
				    
                            </tr>
                            </tbody>
                        </table>
                    </div>


                    <div id="Preslav" class="collapse" data-parent="#accordion">
                        <strong>Title: </strong>Scaling paradigms for large language models
                        <br>
                        <strong>Speaker: </strong><a href="https://www.jasonwei.net/">Jason Wei @ OpenAI</a>
                        <br>
                        <br>
			    <p  style="text-align: justify;">
                        <strong> Abstract: </strong>  
In this talk I will tell you about the role of scaling in the past five years of artificial intelligence.
In the first scaling paradigm, which started around five years ago, our field scaled large language models by training with more compute on more data. Such scaling led to the success of ChatGPT and other AI chat engines, which were surprisingly capable and general purpose. With the release of OpenAI o1, we are at the beginning of a new paradigm where we do not just scale training time compute, but we also scale test-time compute. These new models are trained via reinforcement learning on chain-of-thought reasoning, and by thinking harder for more-challenging tasks can solve even competition-level math and programming problems.
			    </p>
                        <br>
			    <p  style="text-align: justify;"> 
                        <strong>Bio:</strong> 
Dr. Jason Wei is an AI researcher based in San Francisco. He currently works at OpenAI, where he contributed to OpenAI o1, a frontier model trained to do chain-of-thought reasoning via reinforcement learning. From 2020 to 2023, Jason was a research scientist at Google Brain, where his work popularized chain-of-thought prompting, instruction tuning, and emergent phenomena. 
			    </p><br>
                        <br>
                    </div>

                    <div id="Farah" class="collapse" data-parent="#accordion">
                        <strong>Title: </strong>Lifelong Learning Dialogue Systems
                        <br>
                        <strong>Speaker: </strong><a href="https://www.cs.uic.edu/~liub/">Bing Liu @ UIC</a>
                        <br>
                        <br>
                        <p  style="text-align: justify;"> <strong> Abstract: </strong>
Dialogue systems, commonly known as chatbots, have gained escalating popularity in recent times due to their wide-spread applications in carrying out chit-chat conversations with users and task-oriented dialogues to accomplish various user tasks. Existing chatbots are usually trained from pre-collected and manually labeled data. Many also use manually compiled knowledge bases (KBs). Their ability to understand natural language is still limited. Typically, they need to be constantly improved by engineers with more labeled data and more manually compiled knowledge. In this talk, I would like to introduce the new paradigm of lifelong learning dialogue systems to endow chatbots the ability to learn continually by themselves through their own self-initiated interactions with their users and working environments. As the systems chat more and more with users, they become more and more knowledgeable and better and better at conversing.
			</p>
                        <br>
                        <p  style="text-align: justify;"> <strong>Bio:</strong>
Dr. Bing Liu is a Distinguished Professor and Peter L. and Deborah K. Wexler Professor of Computing at the University of Illinois Chicago. He received his Ph.D. in Artificial Intelligence (AI) from the University of Edinburgh. His current research interests include continual/lifelong learning, lifelong learning dialogue systems, sentiment analysis, machine learning and natural language processing. He has published extensively in prestigious conferences and journals and authored five books: one about lifelong machine learning, one about lifelong learning dialogue systems, two about sentiment analysis, and one about Web mining. Three of his papers have received the Test-of-Time awards, and another one received Test-of-Time honorable mention. Some of his works have also been widely reported in popular and technology press internationally. He served as the Chair of ACM SIGKDD from 2013-2017 and as program chair of many leading data mining conferences. He is also the winner of 2018 ACM SIGKDD Innovation Award, and is a Fellow of ACM, AAAI, and IEEE.
			</p><br>
                        <br>
                    </div>

                    <div id="Yue" class="collapse" data-parent="#accordion">
                        <strong>Title: </strong>AutoSurvey: Large Language Models Can Automatically Write Surveys
                        <br>
                        <strong>Speaker: </strong><a href="https://frcchang.github.io/ ">Yue Zhang @ Westlake Unv</a>
                        <br>
                        <br>
                        <p  style="text-align: justify;"> <strong> Abstract: </strong>
This talk introduces AutoSurvey, a speedy and well-organized methodology for automating the creation of comprehensive literature surveys in rapidly evolving fields like artificial intelligence. Traditional survey paper creation faces challenges due to the vast volume and complexity of information, prompting the need for efficient survey methods. While large language models (LLMs) offer promise in automating this process, challenges such as context window limitations, parametric knowledge constraints, and the lack of evaluation benchmarks remain. AutoSurvey addresses these challenges through a systematic approach that involves initial retrieval and outline generation, subsection drafting by specialized LLMs, integration and refinement, and rigorous evaluation and iteration. Our contributions include a comprehensive solution to the survey problem, a reliable evaluation method, and experimental validation demonstrating AutoSurvey's effectiveness.
			</p>
                        <br>
                        <p  style="text-align: justify;"> <strong>Bio:</strong>
Dr. Yue Zhang is a tenured Professor at Westlake University. His research interests include NLP and its underlying machine learning algorithms. His major contributions to the field include psycholinguistically motivated machine learning algorithm, learning-guided beam search for structured prediction, pioneering neural NLP models including graph LSTM, and OOD generalization for NLP. He authored the Cambridge University Press book ``Natural Language Processing -- a Machine Learning Perspective''. He is the PC co-chair for CCL 2020 and EMNLP 2022, and action editor for Transactions for ACL. He also served as associate editor for IEEE/ACM Transactions of Audio Speech and Language Processing (TASLP), ACM Transactions on Asian and Low-Resource Languages (TALLIP), IEEE Transactions on Big Data (TBD) and Computer, Speech and Language (CSL). He won the best paper awards of IALP 2017 and COLING 2018, best paper honorable mention of SemEval 2020, and best paper nomination for ACL 2018 and ACL 2023.
			</p><br>
                        <br>
                    </div>

<!--                     <div id="Vivian" class="collapse" data-parent="#accordion">
                        <strong>Title: </strong> From Bots to Buddies: Making Conversational Agents More Human-Like
                        <br>
                        <strong>Speaker: </strong><a href="https://www.csie.ntu.edu.tw/~yvchen/">Vivian Chen</a> 
                        <br>
                        <br>
                        <p  style="text-align: justify;"> <strong> Abstract: </strong> 
			    While today's conversational agents are equipped with impressive capabilities, there remains a clear distinction between the intuitive prowess of humans and the operational limits of machines. An example of this disparity is evident in the human ability to infer implicit intents from users' utterances, subsequently guiding conversations toward specific topics or recommending appropriate tasks or products. This talk aims to elevate conversational agents to a more human-like realm, enhancing user experience and practicality. By exploring innovative strategies and frameworks that leverages commonsense knowledge, we delve into the potential ways conversational agents can evolve to offer more seamless, contextually aware, and user-centric interactions. The goal is to not only close the gap between human and machine interactions but also to unlock new possibilities in how conversational agents can be utilized in our daily lives.
                        </p><br>
                        <p  style="text-align: justify;"> <strong>Bio:</strong>
                        Dr. Yun-Nung (Vivian) Chen is currently an associate professor in the Department of Computer Science & Information Engineering at National Taiwan University. She earned her Ph.D. degree from Carnegie Mellon University, where her research interests focus on spoken dialogue systems and natural language processing. She was recognized as the Taiwan Outstanding Young Women in Science and received Google Faculty Research Awards, Amazon AWS Machine Learning Research Awards, MOST Young Scholar Fellowship, and FAOS Young Scholar Innovation Award. Her team was selected to participate in the first Alexa Prize TaskBot Challenge in 2021. Prior to joining National Taiwan University, she worked in the Deep Learning Technology Center at Microsoft Research Redmond.
			</p><br>
                        <br>
                    </div> -->

<!--                     <div id="Tanya" class="collapse" data-parent="#accordion">
                        <strong>Title: </strong>Evaluation in the era of GPT-4
                        <br>
                        <strong>Speaker: </strong><a href="https://tagoyal.github.io/">Tanya Goyal</a>
                        <br>
                        <br>
                        <p  style="text-align: justify;">  <strong> Abstract:</strong> 
				As large language models become more embedded in user applications, there is a push to align their outputs with human preferences. But human preferences are highly subjective, making both model alignment and evaluation extremely challenging. In this talk, I will first outline work that highlights this subjectivity, for a relatively well-defined tasks like summarization, and its effects on downstream model evaluations. Next, I will discuss how effectively trained models can capture human preferences and the impact of integrating these models into RLHF pipelines.
			</p>
                        <br>
                        <p  style="text-align: justify;"> <strong>Bio:</strong> 
				Dr. Tanya Goyal is an incoming (Fall 2024) assistant professor of Computer Science at Cornell University. For the 2023-2024 academic year, she is a postdoctoral researcher at the Princeton Language and Intelligence (PLI) group. Her current research focuses on designing scalable and cost-effective evaluation techniques for LLMs. Particularly, she is interested in understanding and modeling the subjectivity in human feedback, and how this affects both evaluation and training of LLMs at scale. Previously, she received her Ph.D. in computer science from the University of Texas at Austin in 2023, advised by Dr. Greg Durrett. Her thesis research focused on building tools to automatically detect attribution errors in generated text.                        
			</p>
			    <br>
                        <br>
                    </div>
 -->
                    <div class="table-responsive">
                        <table class="table">
                            <tbody>
                            <tr align="center">
                                <td>
                                    <a href="#Diyi" data-toggle="collapse">
                                        <figure>
                                            <img src="images/speaker/tianyu-pang.jpg" class="hover2"
                                                  height="185">
                                            <figcaption><h5>Tianyu Pang</h5></figcaption>
                                        </figure>
                                    </a>
                                </td>
                                <td>
                                    <a href="#Joao" data-toggle="collapse">
                                        <figure>
                                            <img src="images/speaker/wenxuan-zhang.jpg" class="hover2"  height="185">
                                            <figcaption><h5>Wenxuan Zhang</h5></figcaption>
                                        </figure>
                                    </a>
                                </td>
				    
                                <td>
                                    <a href="#Daniel" data-toggle="collapse">
                                        <figure>
                                            <img src="images/speaker/taifeng-wang.png" class="hover2"
                                                  height="185">
                                            <figcaption><h5>Taifeng Wang</h5></figcaption>
                                        </figure>
                                    </a>
                                </td>
<!--                                 <td>
                                    <a href="#Huda" data-toggle="collapse">
                                        <figure>
                                            <img src="images/speaker/HudaKhayrallah.jpg" class="hover2"
                                                  height="185">
                                            <figcaption><h5>Huda Khayrallah</h5></figcaption>
                                        </figure>
                                    </a>
                                </td> -->
                            </tr>
                            </tbody>
                        </table>
                    </div>

                    <div id="Diyi" class="collapse" data-parent="#accordion">
                        <strong>Title: </strong> Your LLM is Secretly a Fool and You Should Treat it Like One
                        <br>
                        <strong>Speaker: </strong><a href="https://p2333.github.io/ ">Tianyu Pang @ Sea AI</a>
                        <br>
                        <br>
                        <p  style="text-align: justify;">  <strong> Abstract:</strong> 
In this talk, I will present our recent works on jailbreaking/cheating LLMs and multimodal LLMs (MLLMs). This involves a quick overview of adversarial attacks and shows how LLMs/MLLMs facilitate much more flexible attacking strategies. For examples, we show that a null model that always returns a constant output can achieve a 86.5% LC win rate on AlpacaEval 2.0; we could also jailbreak one million MLLM agents exponentially fast in, say, 5 minutes.
			    </p>
                        <br>
                        <p  style="text-align: justify;">  <strong>Bio:</strong>
Dr. Tianyu Pang is a Senior Research Scientist at Sea AI Lab. He received Ph.D. and B.S. degrees from Tsinghua University. His research interests span the areas of machine learning, including Trustworthy AI and Generative Models. He has published over 40 papers on top-tier conferences and journals including ICML/NeurIPS/ICLR and CVPR/ICCV/ECCV/TPAMI. His published papers have received over 9,000 citations. He is a recipient of Microsoft Research Asia Fellowship (2020), Baidu Scholarship (2020), NVIDIA Pioneering Research Award (2018), Zhong Shimo Scholarship (2020), CAAI Outstanding Doctoral Dissertation Award (2023), WAIC Rising Star Award (2023), and World's Top 2% Scientists (2024).
			</p><br>
                        <br>
                    </div>
                    <div id="Joao" class="collapse" data-parent="#accordion">
                        <strong>Title: </strong>Auto-Arena: Towards Fully Automated LLM Evaluations
                        <br>
                        <strong>Speaker: </strong><a href="https://isakzhang.github.io/">Wenxuan Zhang @ DAMO</a>
                        <br>
                        <br>
                        <p  style="text-align: justify;">  <strong> Abstract: </strong> 
As large language models (LLMs) rapidly evolve, the challenge of evaluating their capabilities becomes increasingly crucial. In this talk, I will discuss the paradigm shift in LLM evaluation, tracing its evolution from traditional static benchmark-based methods to the LLM-as-a-judge approach, and ultimately to the renowned Chatbot Arena platform based on human voting. Throughout this journey, we observe a trend towards automation in various components of the evaluation process. Building on this trend, I will introduce our innovative solution: the Auto-Arena for LLMs. This automated evaluation framework leverages LLM-based agents to streamline the entire assessment process, from generating questions and participating in debates to evaluating one another within a committee. Remarkably, the Auto-Arena produces results that exhibit state-of-the-art correlation with human preferences—all without human intervention. I will conclude by sharing interesting findings from this project and exploring potential future directions in the realm of automated LLM evaluation and LLM improvements.
                        </p><br>
                        <p  style="text-align: justify;"> <strong>Bio:</strong>
Dr. Wenxuan Zhang is currently a research scientist at Alibaba DAMO Academy in Singapore. He received his Ph.D. degree from the Chinese University of Hong Kong and then joined Alibaba Singapore with the Ali Star award. His primary research areas are natural language processing (NLP) and trustworthy AI. His research aims to advance NLP models that are inclusive, supporting diverse languages and cultures through multilingual language models, while also trustworthy by improving the safety and robustness of the models. He has published over 40 papers in top-tier AI conferences and journals, including ICLR, NeurIPS, ACL, EMNLP, SIGIR, WWW, TOIS, and TKDE. He is the core tech lead of the SeaLLMs project (LLMs specialized for Southeast Asian languages), which has received significant community attention with over 200k downloads. He also regularly serves on the (senior) program committees of multiple leading conferences and journals.
			</p><br>
                        <br>
                    </div>


                    <div id="Daniel" class="collapse" data-parent="#accordion">
                        <strong>Title: </strong> Train Large-Scale Language Model with High-Quality Data
                        <br>
                        <strong>Speaker: </strong><a href="https://www.linkedin.com/in/taifeng-wang-61783137/?originalSubdomain=cn">Taifeng Wang @ ByteDance</a>
                        <br>
                        <br>
                        <p  style="text-align: justify;">  <strong> Abstract:</strong> 
In the rapidly evolving field of artificial intelligence, training large-scale language models has emerged as a crucial area of research and development. Today's talk focuses on the significance of training large scale language models with high-quality data. As language models continue to grow in size and complexity, the quality of the training data becomes paramount. High-quality data ensures more accurate and reliable language understanding and generation. It enables the model to capture nuanced language patterns, semantic relationships, and context. We will talk about the various techniques employed to train large-scale language models effectively.
                        </p><br>
                        <p  style="text-align: justify;">  <strong>Bio:</strong> 
Taifeng Wang is currently a principal researcher at ByteDance. He got his master's degree from the University of Science and Technology of China. He is an expert on AI Algorithms with over 20 years of R&D experience, who has served as Principal Researcher at Microsoft Research Asia, AI Director of the Intelligent Engine Department at Ant Financial, and Head of AI Algorithms at Biomap. His research spans the entire spectrum from natural language processing (NLP), graph learning, distributed machine learning, multimodal learning, and AI-driven biopharmaceuticals. He has served as a Senior Area Chair for ACL and is the brilliant mind behind LightGBM, famously known as a "Kaggle leaderboard weapon". Holding 17 Chinese patents and 20 U.S. patents, Taifeng's research has garnered over 16,000 citations on Google Scholar. His team is now working on building the Large Language foundation model for ByteDance.			</p><br>
                        <br>
                    </div>
<!--                     <div id="Huda" class="collapse" data-parent="#accordion">
                        <strong>Title: </strong> Perplexity-Driven Case Encoding Needs Augmentation for CAPITALIZATION Robustness
                        <br>
                        <strong>Speaker: </strong><a href="https://khayrallah.github.io/">Huda Khayrallah</a> 
                        <br>
                        <br>
                        <p  style="text-align: justify;">  <strong> Abstract:</strong> 
				For most NLP models, upper and lower case letters are represented with distinct code-points. In contrast, most people naturally connect upper and lower-cased letters as highly similar and therefore expect NLP models to perform similarly on inputs that only differ in casing. However, that is often not the case, and NLP models are often unstable on non-standard casings. Subword segmentation methods (e.g., BPE (Sennrich et al., 2016) and SPM (Kudo and Richardson, 2018)) handle the sparsity introduced by a variety of linguistic features (e.g. concatenative morphology) by learning a segmentation of words into shorter sequences of characters. However, such methods do not currently handle the sparsity introduced by casing well and can lead to terrible quality on ALL CAPS data. Prior work (Berard et al., 2019; Etchegoyhen and Gete, 2020) overcame the quality drop in machine translation but did so in a way that breaks the encoding optimality of perplexity driven methods, leading to impractical sequence length/runtime. In this work, we re-encode capitalization to allow the perplexity-driven subword segmentation model to learn how to best segment this linguistic feature. Naturally occurring data accurately describes the prevalence of capitalization but underestimates the importance humans ascribe to capitalization robustness. We propose data augmentation to fill this gap. Overall, we increase translation quality on data with different casings (compared to standard SPM), with minimal impact on decoding speed on standard cased data and large speed improvements on ALL CAPS data.
                        </p><br>
                        <p  style="text-align: justify;">  <strong>Bio:</strong>
			Dr. Huda Khayrallah is a senior researcher at Microsoft, working on the Microsoft Translator team. She holds a PhD in computer science from The Johns Hopkins University (JHU), where she was advised by Philipp Koehn. She also holds a bachelor’s in computer science from UC Berkeley. She has worked on a variety of topics in machine translation and NLP including: low resource MT, noisy data in MT, domain adaptation, chatbots, and more.
			</p><br>
                        <br>
                    </div> -->

			
<!--                    <div class="table-responsive">-->
<!--                        <table class="table">-->
<!--                            <tbody>-->
<!--                            <tr align="center">-->
<!--                                <td>-->
<!--                                    <a href="#Alessandro" data-toggle="collapse">-->
<!--                                        <figure>-->
<!--                                            <img src="images/speaker/Alessandro Moschitti.png" class="hover2"  height="185">-->
<!--                                            <figcaption><h5>Alessandro Moschitti</h5></figcaption>-->
<!--                                        </figure>-->
<!--                                    </a>-->
<!--                                </td>-->
<!--                                <td>-->
<!--                                    <a href="#Lidong" data-toggle="collapse">-->
<!--                                        <figure>-->
<!--                                            <img src="images/speaker/lidong_bing.jpeg" class="hover2"-->
<!--                                                  height="185">-->
<!--                                            <figcaption><h5>Lidong Bing</h5></figcaption>-->
<!--                                        </figure>-->
<!--                                    </a>-->
<!--                                </td>-->
<!--                            </tr>-->
<!--                            </tbody>-->
<!--                        </table>-->
<!--                    </div>-->

<!--                    <div id="Alessandro" class="collapse" data-parent="#accordion">-->
<!--                        <strong>Title: </strong>Retrieval-Augmented Large Language Models for Personal Assistants-->
<!--                        <br>-->
<!--                        <strong>Speaker: </strong><a href="https://www.linkedin.com/in/alessandro-moschitti-10999a4/">Alessandro Moschitti</a> -->
<!--                        <br>-->
<!--                        <br>-->
<!--                        <p  style="text-align: justify;"> <strong> Abstract: </strong>-->
<!--				Recent work has shown that Large Language Models (LLMs) can potentially answer any question with high accuracy, also providing justifications of the generated output. At the same time, other research work has shown that even the most powerful and accurate models, such as ChatGPT 4, produce hallucinations, which often invalidated their answers. Retrieval-Augmented LLMs are currently a practical solution that can effectively solve the above-mentioned problem. However, the quality of grounding is essential in order to improve the model, since noisy context deteriorates the overall performance. In this talk, we present our experience with Generative Question Answering, which uses basic search engines and accurate passage rerankers to augment relatively small language models. Interestingly, our approach provides a more direct interpretation of knowledge grounding for LLMs.-->
<!--			</p><br>-->
<!--                        <p  style="text-align: justify;"> <strong>Bio:</strong>-->
<!--                        Dr. Alessandro Moschitti is a Principal Research Scientist of Amazon Alexa AI, where he has been leading the science of Alexa information service since 2018. He designed the Alexa QA system based on unstructured text and more recently the first Generative QA system to extend the answer skills of Alexa. He obtained his Ph.D. in CS from the University of Rome in 2003, and then did his postdoc at The University of Texas at Dallas for two years. He was professor of the CS Dept. of the University of Trento, Italy, from 2007 to 2021. He participated to the Jeopardy! Grand Challenge with the IBM Watson Research center (2009 to 2011), and collaborated with them until 2015. He was a Principal Scientist of the Qatar Computing Research Institute (QCRI) for five years (2013-2018). His expertise concerns theoretical and applied machine learning in the areas of NLP, IR and Data Mining. He is well-known for his work on structural kernels and neural networks for syntactic/semantic inference over text, documented by more than 330 scientific articles. He has received four IBM Faculty Awards, one Google Faculty Award, and five best paper awards. He was the General Chair of EACL 2023 and EMNLP 2014, a PC co-Chair of CoNLL 2015, and has had a chair role in more than 70 conferences and workshops. He is currently a senior action/associate editor of ACM Computing Survey and JAIR. He has led ~30 research projects, e.g., with MIT CSAIL. -->
<!--			</p><br>-->
<!--                        <br>-->
<!--                    </div>-->


<!--                    <div id="Lidong" class="collapse" data-parent="#accordion">-->
<!--                        <strong>Title: </strong>Research and Implementation of Large Language Models at Alibaba DAMO Academy-->
<!--                        <br>-->
<!--                        <strong>Speaker: </strong><a href="https://lidongbing.github.io/">Lidong Bing</a>-->
<!--                        <br>-->
<!--                        <br>-->
<!--                        <p  style="text-align: justify;"> <strong> Abstract:</strong> -->
<!--				Over the past year, Large Language Models (LLMs) have brought about a significant transformation in the field of Natural Language Processing (NLP) and artificial intelligence (AI). This presentation will provide an overview of the research and practical initiatives carried out by Alibaba DAMO Academy in the domain of LLMs. On the practical front, the team has introduced an LLM called <a href="https://huggingface.co/SeaLLMs/SeaLLM-Chat-13b">SeaLLMs</a>, which demonstrates remarkable capabilities across major languages in the ASEAN region. When compared to models with similar parameter sizes, SeaLLMs has achieved state-of-the-art performance on various datasets, spanning from fundamental NLP tasks to complex general task solving. Additionally, SeaLLMs has been meticulously customized to enhance safety in these languages and improve its understanding of local cultures. On the research side, the presenter will introduce several recent projects undertaken by the team to advance the development of superior multilingual LLMs. These initiatives include the creation of a multilingual evaluation benchmark for LLMs, an extensive investigation into multilingual jailbreak, a framework that enhances LLMs by incorporating adaptive knowledge sources, a method for extending context length in pretraining, and a framework aimed at making LLMs more effective for low-resource languages. Lastly, the presenter will offer insights into the directions that the team will investigate in the near future. Additionally, he will provide information about career opportunities at DAMO Academy.-->
<!--                        </p><br>-->
<!--                        <p  style="text-align: justify;"> <strong>Bio:</strong> -->
<!--				Dr. Lidong Bing is the director of the Language Technology Lab at DAMO Academy of Alibaba Group. He received a Ph.D. from The Chinese University of Hong Kong and was a postdoc research fellow at Carnegie Mellon University. His research interests include various low-resource and multilingual NLP problems, large language models and their applications, etc. He has published over 150 papers on these topics in top peer-reviewed venues. Currently, he is serving as an Action Editor for Transactions of the Association for Computational Linguistics (TACL) and ACL Rolling Review (ARR), as well as an Area Chair for AI conferences and Associate Editors for AI journals.                        </p><br>-->
<!--                        <br>-->
<!--                    </div>-->


                </div>
            </div>
        </div>
</section>



<!--
<section id="panelists" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h3>Panel Discussions: Ethics in AI</h3>
                <p>
                    The following speakers have accepted to serve as panelists for the panel discussion at SSNLP 2023.
                    You can view their detailed
                    information by clicking the images. Eduard Hovy and other academic speakers will also be discussants
                    on the panel (TBC).
                </p>

                <div class="accordion" id="accordion2">
                    <div class="table-responsive">
                        <table class="table">
                            <tbody>
                            <tr align="center">
                                <td>
                                    <a href="#liling" data-toggle="collapse">
                                        <figure>
                                            <img src="images/liling.png" class="hover2" width="160" height="192">
                                            <figcaption><h5>Liling Tan</h5></figcaption>
                                        </figure>
                                    </a>
                                </td>
                                <td>
                                    <a href="#shafiq" data-toggle="collapse">
                                        <figure>
                                            <img src="images/shafiq.jpg" class="hover2" align="center" width="160"
                                                 height="192">
                                            <figcaption>
                                                <h5>Shafiq Joty</h5>
                                            </figcaption>
                                        </figure>
                                    </a>
                                </td>
                                <td>
                                    <a href="#guillermo" data-toggle="collapse">
                                        <figure>
                                            <img src="images/Guillermo.png" class="hover2" align="center" width="160"
                                                 height="192">
                                            <figcaption>
                                                <h5>Guillermo Infante</h5>
                                            </figcaption>
                                        </figure>
                                    </a>
                                </td>
                            </tr>
                            </tbody>
                        </table>
                    </div>


                    <div id="liling" class="collapse" data-parent="#accordion2">
                        <strong>Speaker: </strong><a href="https://www.linkedin.com/in/alvations/">Liling Tan</a>
                        <br>
                        <br>
                        <strong>Bio:</strong> Liling Tan is a Research Scientist at at Rakuten Institute of Technology
                        Singapore. Currently, he works on machine translation and language learning technologies.
                        Previously, he was an early stage researcher in Saarland University working on dictionaries,
                        ontologies and machine translation. Before that, he studied at NTU working on crosslingual
                        semantics and multilingual corpora.
                        <br>
                        <br>
                    </div>

                    <div id="shafiq" class="collapse" data-parent="#accordion2">
                        <strong>Speaker: </strong><a href="https://raihanjoty.github.io">Shafiq Joty</a>
                        <br>
                        <br>
                        <strong>Bio:</strong> Shafiq Joty is an Assistant professor at the School of Computer Science
                        and Engineering, NTU. He is also a senior research manager at Salesforce Research. He holds a
                        PhD in Computer Science from the University of British Columbia. His work has primarily focused
                        on developing language analysis tools (e.g., parsers, NER, coherence models), and exploiting
                        these tools effectively in downstream applications for question answering, machine translation,
                        image/video captioning and visual question answering. He was an area chair for ACL-2022 and
                        EMNLP-2022. He gave tutorials on ``Discourse Analysis and Its Applications" at ACL-2022 and at
                        ICDM-2018.
                        <br>
                        <br>
                    </div>

                    <div id="guillermo" class="collapse" data-parent="#accordion2">
                        <strong>Speaker: </strong><a href="https://www.linkedin.com/in/ginfante/?originalSubdomain=sg">Guillermo
                        Infante</a>
                        <br>
                        <br>
                        <strong>Bio:</strong> Guillermo Infante is the Chief Technology Officer of TAIGER, a global
                        Artificial Intelligence
                        company headquartered in Singapore with offices in five other countries across Europe, America
                        and Asia-Pacific.
                        He leads the technology team to develop cognitive solutions that help organisations to optimise
                        operational efficiencies. With over a decade in the computer science and software engineering
                        fields, Guillermo drives research and development projects with Artificial Intelligence and
                        Semantic Technologies.
                        Prior to join TAIGER, he worked as a professor at leading universities of Spain and Latin
                        America. He was also a researcher in the field of Semantics &amp; AI and his work contributed to
                        expand the knowledge base of several technology systems and industries.
                        His career interest is mainly on AI, Natural Language Processing and Understanding, as well as
                        Knowledge Representation and Reasoning. His work has been published in multiple peer-
                        reviewed international journals.
                        Guillermo holds a PhD in Computer Science and a MSc degree in Web Engineering from the
                        University of Oviedo (Spain), and an executive MSc degree in Innovation Management from the
                        EOI Business School (Madrid, Spain).
                        <br>
                        <br>
                    </div>


                </div>

            </div>
        </div>
    </div>
</section>
-->

<section id="organizers" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h2>Organizers</h2>

		<span>
                    <a href="https://www.imda.gov.sg/about-imda/emerging-technologies-and-research">
                    <img src="images/imda.png" width="220" style="margin-right: 30px">
                    </a>
                    <a href="https://nus.edu.sg/">
                        <img src="images/nus.png" width="190" style="margin-right: 20px">
                    </a>
                    <a href="https://www.ntu.edu.sg">
                        <img src="images/ntu.png" width="230" style="margin-right: 20px">
                    </a>
                    <a href="https://www.smu.edu.sg/">
                    <img src="images/smu.png" width="230" style="margin-left: 100px">
                    </a>
                    <a href="https://www.sutd.edu.sg/">
                        <img src="images/sutd.png" width="180" style="margin-left: 80px">
                    </a>
                </span>
		   
                <p>
                    <table class="table" style="font-size: 15px;">
                        <tbody>
		                <tr>
		                    <td>General Chair:</td>
		                    <td>
		                        <p><a href="https://jiayingwu19.github.io/"> Jiaying Wu</a>, National University of Singapore</p>
		                    </td>
		                </tr>

		                <tr>
		                    <td>Local Chairs:</td>
		                    <td>
		                        <p><a href="https://scholar.google.com.sg/citations?user=4q8VxIIAAAAJ"> Ambuj Mehrish</a>, Singapore University of Technology and Design</p>
		                        <p><a href="https://mingshanhee.com/"> Ming Shan Hee</a>, Singapore University of Technology and Design</p>
		                        <p><a href="#">Gerard Christopher Yeo</a>,  National University of Singapore</p>
		                    </td>
		                </tr>

		                <tr>
		                    <td>Program & Invitation Chairs:</td>
		                    <td>
		                        <p><a href="https://dengyang17.github.io/"> Yang Deng</a>,  Singapore Management University</p>
		                        <p><a href="https://tuanluu.github.io/"> Anh Tuan Luu</a>,  Nanyang Technological University</p>
		                    </td>
		                </tr>

		                <tr>
		                    <td>Industry Relations Chair:</td>
		                    <td>
		                        <p><a href="https://sites.google.com/view/yixin-homepage"> Yixin Cao</a>, Fudan University</p>
		                    </td>
		                </tr>

		                <tr>
		                    <td>Publicity  Chairs:</td>
		                    <td>
		                        <p><a href="https://personal.ntu.edu.sg/wangwy/"> Wenya Wang</a>,  Nanyang Technological University</p>
		                        <p><a href="https://haofei.vip/"> Hao Fei</a>,  National University of Singapore</p>
		                    </td>
		                </tr>

		                <tr>
		                    <td>Advisory Committee:</td>
		                    <td>
		                        <p><a href="https://www.comp.nus.edu.sg/~kanmy">Min-Yen Kan</a>, National University of Singapore</p>
		                        <p><a href="https://people.sutd.edu.sg/~sporia/">Soujanya Poria</a>, Singapore University of Technology and Design</p>
		                        <p><a href="https://info.roylee.sg/home">Roy Lee</a>, Singapore University of Technology and Design</p>
		                    </td>
		                </tr>

				
			</tbody>
                   </table>

                </p>
		    
            </div>
        </div>
    </div>
</section>


<section id="partners" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h2>Partners</h2>
                <br>
<!-- 		<h3>Partners</h3> -->

                <div class="spoil" style="display: flex;flex-direction: row;justify-content: center;align-items: center;">
<!--                    <a > A*STAR</a>-->
                    <a href="https://www.a-star.edu.sg/"> <img src="images/sponsor/i2r.png" width="280" style="margin-left: 0px"/></a>
                    <a href="https://job.toutiao.com/s/iBqWUUXB"> <img src="images/sponsor/ByteDance.png" width="250" style="margin-left: 60px"/></a>
                </div>
		    
<!--                <div class="spoil" style="display: flex;flex-direction: column;align-items: center;margin-top: 30px">-->
<!--&lt;!&ndash;                    <a > <img src="images/sponsor/gold-tier.png" width="200" style="margin-right: 0px"/></a>&ndash;&gt;-->
<!--                    <a href="https://www.bytedance.com/"> <img src="images/sponsor/ByteDance.png" width="250" style="margin-left: 150px"/></a>-->
<!--                </div>-->
		    
                <div class="spoil" style="display: flex;flex-direction: row;justify-content: center;align-items: center;margin-top: 30px">
<!--                    <a > <img src="images/sponsor/silver-tier.png" width="200" style="margin-right: 0px"/></a>-->
                    <a href="https://www.alibabagroup.com/">  <img src="images/sponsor/Alibaba-DAMO.png" width="250" style="margin-left: 0px"/></a>
                    <a href="https://sail.sea.com/"> <img src="images/sponsor/sea-logo.png" width="270" style="margin-left: 60px"/></a>
                </div>

<!--                <div class="spoil" style="display: flex;flex-direction: column;align-items: center;margin-top: 30px">-->
<!--&lt;!&ndash;                    <a > <img src="images/sponsor/bronze-tier.png" width="200" style="margin-right: 0px"/></a>&ndash;&gt;-->
<!--&lt;!&ndash;                    <a href="https://ctic.nus.edu.sg/index.html"> <img src="images/sponsor/CTIC-NUS-logo.png" width="150" style="margin-left: 70px"/></a>&ndash;&gt;-->
<!--                    <a href="https://sail.sea.com/"> <img src="images/sponsor/sea-logo.png" width="270" style="margin-left: 50px"/></a>-->
                </div>
		    
            </div>
        </div>
    </div>
</section>

<!--
<section id="photos" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h2>Photos</h2>
                <div id="carouselExampleIndicators" class="carousel slide" data-ride="carousel">
                    <ol class="carousel-indicators">
                        <li data-target="#carouselExampleIndicators" data-slide-to="0" class="active"></li>
                        <li data-target="#carouselExampleIndicators" data-slide-to="1"></li>
                    </ol>
                    <div class="carousel-inner">
                        <div class="carousel-item active">
                            <img class="d-block w-" src="images/ssnlp/hengji1.jpg" alt="First slide">
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-" src="images/ssnlp/hengji2.jpg" alt="Second slide">
                        </div>
                    </div>
                    <a class="carousel-control-prev" href="#carouselExampleIndicators" role="button" data-slide="prev">
                        <span class="carousel-control-prev-icon" aria-hidden="true"></span>
                        <span class="sr-only">Previous</span>
                    </a>
                    <a class="carousel-control-next" href="#carouselExampleIndicators" role="button" data-slide="next">
                        <span class="carousel-control-next-icon" aria-hidden="true"></span>
                        <span class="sr-only">Next</span>
                    </a>
                </div>
            </div>
        </div>
    </div>
</section>
-->

<section id="location" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h2>Location</h2>
                <p>
                 <b>SSNLP 2024</b> will be held at the <b>Mapletree Business City, Town Hall Auditorium, (10 Pasir Panjang Road, Singapore 117438</b>.
                </p>
            <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3988.8309638555306!2d103.7960500114154!3d1.2746971618056253!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x31da1b67237ce9f7%3A0x4a5bf21c011fc61b!2sMBC%20Town%20Hall%20-%20Auditorium!5e0!3m2!1sen!2ssg!4v1728783977344!5m2!1sen!2ssg" width="700" height="500" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
        </div>
    </div>

</section>

<section id="past-ssnlp" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h2>Past SSNLP</h2>
                <ul>

                    <li>
                    · <a href="https://wing-nus.github.io/ssnlp-2023/">SSNLP 2023</a>.  Held at NUS.
                  </li>
                    <li>
                    · <a href="https://github.com/WING-NUS/SSNLP-2022">SSNLP 2022</a>.  Held at NUS.
                  </li>
                  <li>
                    · <a href="https://ssnlp.org/">SSNLP 2020</a>.  Held 100% virtually.
                  </li>
                  <li>
                    · <a href="https://wing-nus.github.io/SSNLP-2019">SSNLP 2019</a>. Held at I2R.
                  </li>
                  <li>
                    · <a href="https://event.statnlp.org/">SSNLP 2018</a>.  Inaugural event at SUTD.
                  </li>
                </ul>
                </p>
                <!--                <p id="h.p_Xe61aUT8vVF4" class="zfr3Q">Twitter: <a class="dhtgD"-->
                <!--                                                                   href="https://twitter.com/to-be-confirmed"-->
                <!--                                                                   target="_blank" rel="noopener">https://twitter.com/to-be-confirmed</a>-->
                <!--                </p>-->
                </p>
            </div>
        </div>
    </div>
</section>

<section id="contact" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h2>Contact Us</h2>
                <p>
                <p id="h.p_4XXDjs_mNTFP" class="zfr3Q">Please feel free to reach out if you have any inquiries:			
                    <a href="mailto:ambuj_mehrish@sutd.edu.sg" target="_blank" rel="noopener">Ambuj Mehrish</a>,
                    <a href="mailto:mingshan_hee@mymail.sutd.edu.sg" target="_blank" rel="noopener">Ming Shan Hee</a> and
                    <a href="mailto:e0545159@u.nus.edu" target="_blank" rel="noopener">Gerard Christopher Yeo</a>.
<!--                     <a href="mailto:jiayingw@nus.edu.sg" target="_blank" rel="noopener">Wu Jiaying</a>. -->
                </p>
            </div>
        </div>
    </div>
</section>

<footer class="py-5 bg-dark">
    <div class="container" style="text-align: center;">
        <!--        <a href="https://twitter.com/to-be-confirmed"><i class="fa fa-twitter fa-2x"></i></a>-->
        <!--        <a href="#"><i class="fa fa-facebook fa-2x"></i></a>-->
        <p><span style="color: white; ">Copyright &copy; SSNLP 2024 | <a href="https://wing.comp.nus.edu.sg/">NUS WING</a>
        </p>
    </div>
</footer>

<!-- Bootstrap core JavaScript -->
<script src="vendor/jquery/jquery.min.js"></script>
<script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

<!-- Plugin JavaScript -->
<script src="vendor/jquery-easing/jquery.easing.min.js"></script>

<!-- Custom JavaScript for this theme -->
<script src="js/scrolling-nav.js"></script>


<script src="vendor/bootstrap/js/popper.js"></script>
<script src="vendor/select2/select2.min.js"></script>
<script src="js/main.js"></script>

</body>

</html>
